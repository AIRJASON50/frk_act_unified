Robotics: Science and Systems 2019  
Freiburg im Breisgau, June 22-26, 2019

## **接触任务中的运动和力生成：一种动力学系统方法**

**摘要**— 许多任务要求机器人与表面接触，无论是支撑、抛光还是抓取物体。机器人必须在接触时和接触中都控制力，这一点至关重要。虽然存在许多用于接触控制的解决方案，但它们都无法提供所需的鲁棒性以适应现实世界中的不确定性，例如物体在接触前和接触后的突然位移。适应此类干扰需要在飞行中重新规划轨迹和力。动力学系统 (DS) 提供了一个即时重新规划轨迹的框架。然而，它们仅限于运动控制。我们在此扩展此框架，以通过 DS 生成接触力和轨迹。该框架还允许调节阻抗，以显示刚性以保持接触，以及柔顺性以确保与人类的安全交互。我们在使用 KUKA LWR 4+ 机械臂的单臂和双臂设置中验证了该方法。我们证明该方法允许：1) 在施加大力时实现平滑接触；2) 在扫描非线性表面时保持期望的接触力，即使表面移动；3) 平稳抓取和举起空中的物体，并实时重新平衡力以保持抓取，即使受到强烈外部干扰。

## **I. 引言**

力控制是机器人学中的一个重要课题，尤其是在当今，许多任务要求机器人在动态变化的环境中与人类互动（图 1）。物体操作、表面操作、手术中的远程操作是力控制对意外情况作出反应至关重要的几个例子。机器人不仅必须实时适应，而且必须对周围环境的不确定性表现出鲁棒性。力控制方法可分为两大类：直接力控制，其中通过明确的力反馈闭环实现目标力（和位置）；以及间接力控制，其中通过阻抗控制律控制相互作用力 \[1\]。

直接力控制仍然深受 1981 年引入的混合位置/力控制的影响 \[2\]。这种方法将任务分解为两个正交解耦的子空间，这些子空间是任务特定的 \[3\]，并且位置和力分别控制。从自由运动到接触运动的转换分阶段进行。在自由运动中，位置控制器在所有控制方向上驱动机器人。一旦机器人接触，位置控制器就切换到混合力/位置控制器。这种方法的优点是它确保了精确的位置和力跟踪。然而，由于它忽略了机器人与环境之间的交互动力学，因此在面对干扰和不确定性时缺乏鲁棒性，并可能导致运行时接触不稳定或接触丢失 \[4\]。

阻抗控制作为这些缺点的一些解决方案被提出 \[5\]。阻抗控制明确考虑了与环境的交互动力学。它通过质量-弹簧-阻尼系统模拟交互力与位置偏差之间的动态关系。当力由运动偏差产生时，该关系称为阻抗；反之则称为导纳。阻抗控制器适用于在接触任务的所有阶段（非接触、过渡和接触）提供柔顺行为 \[6\]，但由于对环境（例如，位置和刚度）的部分了解，它们在跟踪力方面的能力有限。为了克服这一限制，文献中通常采用两种不同的策略：阻抗和设定点自适应。阻抗自适应根据力、位置或速度测量在线调整阻抗参数（例如，惯性、阻尼和刚度）以改善跟踪 \[7, 8, 9, 10\]。设定点自适应方法通过根据力跟踪误差或环境刚度变化的实时估计来调整阻抗设定点（例如，参考位置）来改善力跟踪 \[11, 12, 13, 14, 15\]。其他策略使用阻抗控制，但与直接力控制结合使用，以提供精确的力跟踪和机器人对外部力的柔顺行为 \[16, 17\]。

图 1：两个柔顺机械臂抓取一个纸板箱（左上）。人类通过改变其姿态（右上和左下）和打破抓取（右下）来操纵系统，而不会危及安全和稳定性。

尽管上述工作在运动和力跟踪性能方面有效，但其方法对实时干扰的鲁棒性要么未提及，要么仅限于小干扰，例如表面位置或环境刚度 \[8, 13, 14, 15\]。诸如人类互动引入的大干扰并未得到解决。例如，让我们考虑一个场景，人类操作员监督机器人对表面执行抛光任务，如图 2 所示。在任何时候，人类都可能停止机器人或将其从表面拉开（例如，打破接触）以监控任务的当前执行。在这种情况下，机器人“反应”而不仅仅是使用阻抗控制抑制干扰（这仅对小干扰有效）至关重要。为了正确反应，机器人需要从干扰状态重新规划接触任务的执行。这种反应性需要连续和流畅，因为人类行为可能具有高度动态性。在当前方法中，用时间索引参考表示位置和力曲线是实现对大干扰快速反应的主要缺点；参见 \[14, 15\] 作为使用时间相关任务表示（基于动态运动基元）的示例。相比之下，在状态相关和时间不变的任务表示中，人类干扰可以通过机器人状态的变化来捕获，这些变化用于任务的重新规划。

图 2：机械臂与表面接触以执行（圆形）抛光任务（左上）。我们的策略允许人类在机器人移动到表面时安全地与机器人互动（右上），随时打破接触（左下），并移动表面（右下），而不会影响系统的稳定性。

在这项工作中，我们设计了一种控制策略，以在对实时大干扰具有鲁棒性的情况下执行接触任务。如图 1 和图 2 所示，控制器不仅对人类交互（例如，停止机器人、打破接触和任意移动机器人）作出反应，而且对环境中的意外变化（例如，表面/物体的位置和方向）作出反应。该控制器旨在用于工业 4.0，其中机器人需要执行灵巧的接触任务，同时对其人类同事保持安全 \[18\]。为此，我们建议通过时间不变动力学系统 (DS) 将期望的运动和接触力曲线组合在一个数学表达式中来编码接触任务。DS 提供非常快速的反应性，并能够实时重新规划轨迹，这已在平稳捕获飞行中的物体 \[19\] 或在表面上到达和移动 \[20\] 中得到证明。它们也适用于编码从人类演示中学习的任务 \[21\] 和生成提供柔顺和被动机器人行为的阻抗控制律 \[22\]。在本文中，我们通过扩展时间不变的基于 DS 的控制框架来执行接触任务，从而为这方面的文献做出贡献。我们提出了一种基于机器人标称任务动力学局部调制策略，以在机器人接近表面时生成期望的运动和接触力。因此，该策略提供：

* 稳定和准确的运动和接触力生成。  
* 在接触任务的所有阶段（自由运动、接触时和接触中）都表现出柔顺行为。  
* 对实时干扰的鲁棒性。

我们将在第二节中介绍我们的方法。我们将在第三节中通过两种不同的现实场景对其进行评估：在非平面表面上的抛光任务和到达、抓取和操作任务。我们将在第四节中对所获得的方法和结果以及未来的工作进行讨论。

## **II. 提出的方法**

自主动力学系统通常将状态变量（例如，实际位置 x）作为输入，并返回该变量的变化率（例如，期望速度 x˙d​=f(x)）。它可以看作是描述空间中任何给定位置的期望行为的速度矢量场。

如图 3 所示，我们假设存在一个标称 DS f(x)，它使机器人与表面接触并在表面上移动。我们假设接触表面不可穿透，并且我们明确表达了空间中所有点的法向量 n(x) 和到表面的距离 Γ(x)。标称 DS 应满足：

{f(x)⋅n(x)=0f(x)⋅n(x)\>0​in contactin free motion​(1)  
这种动力学可以从人类演示中学习并进行局部调制以满足这些约束 \[21, 23\]。一旦机器人位于表面上，它必须沿表面法线方向施加一个状态相关的期望力曲线 Fd​(x)∈\[0,Fmax​\]，其中 (Fmax​\>0)。此后，我们展示了如何调制标称 DS 以生成接触力以及运动。

图 3：机器人由标称 DS 驱动，与表面接触并向目标移动的示意图，从初始位置 x0​ 开始。到表面的法向距离 Γ(x) 和法向量 n(x) 可以使用不同的学习算法学习，例如支持向量回归 (SVR) \[24\] 或高斯过程回归 (GPR) \[25\]。这里，我们使用高斯核的 SVR (C=100, ϵ=0.01, σ=0.20)。

### **A. 机器人动力学与控制**

生成的接触力不仅是期望运动的结果，也是机器人动力学的结果。我们表达三维笛卡尔空间中 N 自由度机器人机械手的动力学：

M(x)x¨+C(x,x˙)x˙=Fc​+Fe​(2)  
其中 x∈R3 表示机器人的位置，M(x)∈R3×3 是质量矩阵，C(x,x˙)x˙∈R3 是离心力，而 Fc​∈R3 和 Fe​∈R3 分别表示控制力和外部力。方程 (2) 假设重力 g(x)∈R3 已被补偿。控制力 Fc​ 允许跟踪期望的速度曲线 x˙d​∈R3，并从 \[22\] 中的 DS-阻抗控制器获得：

Fc​=D(x)(x˙d​−x˙)=d1​x˙d​−D(x)x˙(3)  
其中 D(x)∈R3×3 是一个状态变化的阻尼矩阵，其构造方式使得第一个特征向量与具有正特征值 d1​∈R+ 的期望动力学 x˙d​ 对齐。方程 (3) 中的第一项表示沿期望动力学的驱动力，其中 d1​ 作为阻抗增益出现。最后一项是阻尼力，可以通过 D(x) 的最后两个特征值 (d2​ 和 d3​∈R+) 进行操作，以选择性地抑制与期望速度正交的干扰。

在本文中，DS 仅应用于末端执行器的平移。期望末端执行器姿态（详细信息参见附录 A）使用轴角表示法进行跟踪。测量和期望姿态分别由 R=\[xEyEzE\]∈R3×3 和 Rd​=\[xdE​ydE​zdE​\]∈R3×3 表示。姿态误差计算为 R^=Rd​RT∈R3×3，并提取相应的轴角表示来计算使用 PD 状控制律的控制力矩。由控制力矩和力（例如，Fc​）形成的控制力矩然后使用机器人的雅可比矩阵 J∈R6×N 转换为关节扭矩。因此，我们假设机器人具有扭矩传感能力并受扭矩控制。扭矩控制机器人允许柔顺交互控制；特别是阻抗控制在与刚性环境交互中表现出令人满意的性能 \[26\]，这在我们的工作中也是如此。

### **B. 基于 DS 的接触任务策略**

为了用单个 DS 实现期望的运动和力曲线，我们将系统分解如下：

x˙d​=f(x)+fn​(x)(4)  
其中 x˙d​ 是期望速度曲线，fn​(x) 是一个仅沿垂直于表面的方向应用的调制项。将方程 (4) 插入方程 (3)，控制力变为：

Fc​=d1​f(x)+d1​fn​(x)−D(x)x˙(5)  
第一项表示沿标称动力学的驱动力，第三项是阻尼力，而第二项表示沿垂直于表面的法线方向的调制力，我们设计如下：

fn​(x)=d1​Fd​(x)​n(x)(6)  
作为该策略的说明，在图 4 中，图 3 中所示的标称 DS 被调制以在机器人到达表面时产生接触力。在与表面接触之前，期望和标称 DS 对齐并相同。接近接触时，产生法线调制分量并调制标称 DS 以产生期望力。为了说明我们方法在面对干扰时的鲁棒性，当机器人移动时，外部力将机器人从表面推开。调制后的 DS 通过与标称 DS 重新对齐来对干扰做出反应。一旦干扰消失，机器人到达表面并向目标移动，同时施加期望的接触力。

图 4：在非平面表面上到达和移动任务中的调制方法示意图。机器人由调制后的 DS 驱动，并受到垂直于表面的干扰（虚线）。

当控制机器人与未知环境交互时，应确保交互对于性能和安全目的都是稳定的。实现稳定的充分条件是确保整个系统的无源性 \[27, 28\]。这意味着系统永远不会产生额外的能量，或者换句话说，系统的总能量受初始存储能量加上从与环境交互中注入系统的能量的限制。为了实现我们方法的无源性和稳定性，我们提出了一种基于能量箱 \[29\] 的公式，以监控系统中的能量流并防止控制动作产生额外的能量。公式的详细信息在附录 B 中提供。

### **C. 在到达、抓取和操作任务中的应用**

图 5：使用两个机械臂到达、抓取和操纵物体的场景

在本节中，我们研究了如何将调制策略应用于使用两个机械臂到达、抓取和操纵物体这一具有挑战性的任务。此处介绍的公式在第 III-B 节中进行了实验评估。首先，让我们考虑图 5 所示的场景。用于描述问题的主要变量在表 I 中提供。在本节的其余部分，上标 L 和 R 将分别指代左机器人和右机器人。

表 I：用于描述双机器人到达、抓取和操作任务的主要变量。

| 变量 | 描述 |
| :---- | :---- |
| xL,x˙L,x˙dL​ | 左机器人工具位置、速度和期望动力学 |
| xR,x˙R,x˙dR​ | 右机器人工具位置、速度和期望动力学 |
| xoC​ 和 xoD​ | 测量物体中心位置和尺寸向量 |
| xC 和 xD | 测量中心位置和两个机器人之间的距离向量 |
| xdC​ 和 xdD​ | 期望中心位置和距离向量 |
| x˙dC​ 和 x˙dD​ | 期望中心位置和距离向量动力学 |

我们可以从中得出以下关系：

x˙R=x˙C​+2x˙D​x˙L=x˙C​−2x˙D​(8)  
为了在任务期间到达和操纵物体，我们选择通过控制期望的机器人中心位置 xdC​ 和距离向量 xdD​ 来耦合机器人的运动，使用简单的线性动力学：

{x˙dC​=AC​(xdC​−xC)x˙dD​=AD​(xdD​−xD)​(9)  
其中 AC​ 和 AD​ 是正增益对角矩阵。  
基本上，x˙dC​ 指定了机器人中心的期望定位行为，而 x˙dD​ 定义了在物体表面上的期望闭合行为。在到达阶段，可以将 xdC​ 和 xdD​ 分别设置为 xoC​ 和 xoD​，并在操纵阶段进行修改。  
机器人的中心位置 xC 和距离向量 xD 是根据其工具尖端位置 xR 和 xL 计算的：

xC=2xL+xR​xD=xR−xL(7)  
为了执行任务的抓取部分，我们使用第 II-B 节中介绍的调制策略。首先，我们引入标称 DS fR(xL,xR) 和 fL(xL,xR)。标称 DS 应使每个机器人与目标表面（例如物体表面）接触。这个作用由 x˙dD​ 实现。根据方程 (8)，标称 DS 定义为：

fR(xL,xR)=−fL(xL,xR)=2x˙dD​​(10)  
一旦机器人到达物体表面，它们就应该生成期望的接触力曲线 Fd​(xL,xR)≥0，假设两者相同。为此，法向调制项定义如下：

fni​(xL,xR)=d1i​Fd​(xL,xR)​nii=L,R(11)  
力的作用方向 nR 和 nL 从期望距离向量中导出。对于一个盒子（有两个平行表面），它们对两个机器人来说是相反的：

nL=−nR=∣∣xdD​∣∣xdD​​(12)  
由此，可以最终表达期望的机器人速度：

x˙di​=fi(xL,xR)+fni​(xL,xR)+x˙dC​i=L,R(13)  
这包括期望的机器人中心动力学 x˙dC​，其需要适当定位机器人中心。然后使用 DS 阻抗控制器（方程 3）跟踪调制后的 DS。最后，在附录 C 中，我们展示了如何为这种双手动任务保持无源性。

## **III. 实验评估**

在本节中，我们将在两个现实世界任务中评估所提出的基于 DS 的策略：a) 使用单个机械臂机器人抛光非平面表面；b) 使用两个机械臂到达、抓取和操纵物体。我们评估该方法生成所需力曲线的能力，以及在不同类型的干扰下（通过在接触之前和期间意外移动表面/物体，或打破接触）这样做的能力。这些实验评估可以在在线视频中观看：[https://youtu.be/lz0uxUEVc3g](https://youtu.be/lz0uxUEVc3g)。

### **A. 非平面表面上的抛光任务**

DS 调制策略首先在非平面表面上的圆形抛光任务中进行测试，如图 2 所示。一个 7 自由度机械臂 (KUKA LWR IV+) 用于执行任务。机器人配备了执行器上的关节扭矩传感器，可以进行扭矩控制。一个 6 轴 ATI 力/扭矩传感器也安装在末端执行器上，其上连接了一个 3D 打印的手指工具。非平面刚性表面通过加热变形有机玻璃板制成。它安装在一个木板上，其姿态由运动捕捉系统跟踪。机器人的行为在一个简单场景中进行评估：机器人与目标表面接触以在表面上执行圆形运动，同时施加所需的接触力并经历来自人类的干扰。实施的技术细节在附录 D-A 中提供。

图 6：各种人类干扰下的抛光任务：测量力与期望法向力。

图 6 显示了实验期间记录的测量和期望力曲线。在没有经历任何干扰的情况下，机器人首先接触表面执行抛光任务。在此期间，力的生成相对准确，RMS 力误差约为 1.9 N（期望力的 19%）。一段时间后，人类通过将机器人从表面拉开来故意打破接触。在此阶段没有观察到不稳定。一旦被人类释放，机器人只需沿着 DS 的流回到表面以执行任务。然后，当机器人在与表面接触时，人类通过推动和阻止机器人来与系统交互。测量的力保持平滑，表明交互安全稳定。最后，在第二次打破接触后，机器人再次接触表面，人类暂时改变表面的倾斜度。机器人平稳地顺从干扰而没有变得不稳定。

### **B. 到达、抓取和操作任务**

第二次实验评估是使用两个 KUKA LWR IV+ 机器人进行的，以到达和抓取一个纸板箱，如图 1 所示。该箱子质量为 0.65±0.05 kg，由运动捕捉系统跟踪以获取其姿态。两个机器人都在末端执行器上配备了一个 6 轴 ATI 力/扭矩传感器，其上安装了一个用于抓取的平面手掌。评估场景旨在使两个手臂在人类前来并与系统互动之前到达并抓取物体，通过移动它、改变其方向甚至打破抓取。实施基于第 II-C 节，而技术细节在附录 D-B 中提供。

图 7：各种人类干扰下的到达、抓取和操作任务：(a)：测量接触力 (FRTnR,FLTnL) 和期望接触力 (Fd​(xL,xR)) / (b)：机器人能量箱 sL​ 和 sR​（参见附录 C）。

图 7a 说明了测量和期望接触力。当物体被抓取且没有人类干扰时，两个机器人的 RMS 力误差约为 1.7 N（期望力的 11.3%）。到达和抓取阶段的非接触/接触过渡是平滑的，当人类故意打破抓取时，力曲线中没有观察到不稳定。同样，尽管抓取后施加在系统上的干扰（例如，对箱子的快速冲击、改变系统姿态），测量力仍然保持平滑，保证了稳定性和令人满意的柔顺行为。

图 7b 说明了两个机器人能量箱的行为（参见附录 C）。能量箱初始化为最大允许水平，设置为 4.0 J。当机器人最初向物体移动时，能量主要被耗散。然而，这种耗散的能量不能存储在能量箱中，因为它们已经满了。接近接触时，开始产生期望的接触力，而机器人仍然轻微移动。这些非无源动作通过从能量箱中提取能量来实现。一旦物体被抓取，能量箱水平保持不变，直到人类移动机器人以举起物体。这种耗散的能量存储在能量箱中，但由于相互作用而非对称。当人类对物体施加快速冲击时，能量箱水平几乎没有变化，因为机器人几乎没有移动。然后，将系统向左移动（从人类的角度来看）导致右臂产生额外的能量，因为它向施加力的方向移动，而左机器人则耗散能量。从右机器人能量箱中提取了大量能量以执行此非无源动作并保持抓取。当将系统推向右侧时，会发生相反的行为，左机器人产生能量，右机器人耗散能量，导致其相关的能量箱分别被耗尽和填充。类似的推理可以应用于其他干扰阶段，其中人类移动手臂以改变物体姿态或打破抓取。

## **IV. 总结与结论**

在这项工作中，我们提出了一种动力学系统方法，用于在机器人机械手接触任务中生成运动和力。该策略基于对标称 DS 的局部调制，允许机器人到达目标表面并在其上移动。DS 框架的使用在运动和力生成方面提供了灵活性和流畅性，以及对实时干扰的鲁棒性。与传统阻抗控制器一样，接触力的生成是隐式实现的，并导致相对准确的跟踪性能，正如实验结果所示，尽管没有力反馈。此外，实验证实了我们对稳定性和无源性的理论证明，其中机器人的行为在剧烈的人类干扰（例如打破接触）下是平滑和柔顺的。该方法反过来假设机器人动力学（重力等）已得到补偿并且接触表面近似已知。在实践中假设这些条件并非总是可能的，只要运动和力中的误差相对于任务容差较小，这是合理的。本文中介绍的两个现实世界评估场景就是这种情况。但是，如果误差太大，则无法正确完成任务。对于接触任务，这些误差主要来自环境（例如，表面位置、表面法线、摩擦）、机器人模型、测量噪声和其他未建模动力学中的不确定性。然而，这些不确定性中的大多数是结构性的，可以建模或校正。机器人可以通过与表面的交互在线学习或适应这些不确定性。在未来的工作中，我们将探索这些方向，并研究如何调整我们基于 DS 的接触任务策略以应对不确定性并提高任务跟踪。

## **附录 A**

### **期望末端执行器姿态曲线**

在这项工作中，机器人末端执行器的期望姿态曲线是根据到目标表面的距离定义的。在接触阶段，末端执行器的 zE 轴被控制以与表面的法向量 n(x) 对齐。为了生成平滑的姿态曲线，使用四元数表示很方便。令 q 和 qn​ 分别表示与测量姿态和垂直于表面（与 n(x) 对齐）的四元数。期望四元数 qd​(x) 通过使用球面线性插值 (SLERP) 在 q 和 qn​ 之间插值获得：

qd​(x)=sin(Ω)sin(Ω(1−w(x)))q+sin(Ωw(x))qn​​(14)  
其中 Ω=qTqn​，而 w(x)∈\[0,1\] 是一个插值参数，可以设计为到表面距离 Γ(x) 的函数。对于 w(x)，我们选择：

w(x)=1−tanh(κΓ(x))(15)  
其中 κ\>0 控制末端执行器姿态应基于法向距离与法向量对齐的速度。然后，姿态误差可以通过将 qd​(x) 转换为 Rd​ 后使用第 II-A 节中描述的方法进行校正，或者以类似的方式通过使用四元数代数导出轴角误差表示进行校正。

## **附录 B**

### **无源性分析：单个机器人**

我们首先假设标称 DS f(x) 由保守部分 fc​(x) 和非保守部分 fr​(x) 组成：

f(x)=fc​(x)+fr​(x)(16)  
其中 fc​(x) 源自一个势函数 Vc​(x)，使得：

fc​(x)=−∇Vc​(x)(17)  
然后，我们考虑一个包含机器人动能和势函数 Vc​(x) 的存储函数 W(x,x˙)：

W(x,x˙)=21​x˙TM(x)x˙+d1​Vc​(x)(18)  
使用方程 (17)， W(x,x˙) 的变化率是：

W˙(x,x˙)=x˙TM(x)x¨+21​x˙TM˙(x)x˙−d1​x˙Tfc​(x)(19)  
将方程 (2) 中的 M(x)x¨ 代入，并使用 M˙(x)−2C(x,x˙) 的斜对称性，方程 (19) 简化为：

W˙(x,x˙)=x˙TFc​+x˙TFe​−d1​x˙Tfc​(x)(20)  
最终将 Fc​ 替换为方程 (5) 导致：

W˙(x,x˙)=d1​x˙Tfr​(x)+d1​x˙Tfn​(x)−x˙TD(x)x˙+x˙TFe​(21)  
可以改写为：

W˙(x,x˙)=pr​+pn​−pd​+x˙TFe​(22)  
其中 pd​=x˙TD(x)x˙，pr​=d1​x˙Tfr​(x) 和 pn​=d1​x˙Tfn​(x) 分别表示耗散功率、由于标称 DS 的非保守部分产生的功率以及法向调制项产生的功率。由于 D(x) 的定义（参见第 II-A 节），我们可以确保 pd​≥0，而方程 (22) 中前两项的符号不确定。因此，我们不能保证系统相对于环境的无源性。为了恢复无源性，我们考虑一种基于能量箱 \[29\] 的方法，以监控系统中的能量流并防止控制动作引起的不稳定 \[30, 31, 32\]。能量箱基本上是一个具有给定初始和最大（允许）水平的能量储存器。系统耗散的能量用于填充能量箱，从能量箱中提取能量以暂时执行潜在的非无源动作。只要存储未耗尽，就允许提取能量，从而保持整个系统（包括能量箱）的无源性。

因此，让我们引入一个虚拟能量箱状态 s，它存储系统中主要来自阻尼项 pd​ 的耗散能量。我们使用此能量来调制标称 DS，而不会违反无源性。由此产生的能量流由能量箱的动力学控制，该动力学与机器人的状态（x 和 x˙）耦合如下：

s˙=α(s)pd​−βr​(s,pr​)pr​−βn​(s,pn​)pn​(23)  
标量函数 α(s)、βr​(s,pr​) 和 βn​(s,pn​) 控制虚拟能量箱与机器人之间的能量流。让我们将 sm​ 定义为允许存储在能量箱中的最大能量水平。为了确保 s 保持在 0 和 sm​ 之间，我们定义标量函数，使得：

α(s)=Υsm​−δs​,sm​−​(s)βi​(s,pi​)=⎩⎨⎧​001​if s\<0 and pi​\>0if s\>sm​ and pi​\<0otherwise​i=r,n(24)  
其中 s∈\[0,sm​\]，而函数 Υa,b−​(x) 提供从 1 到 0 的平滑过渡，随着 x 从 a 变到 b：

Υa,b−​(x)=⎩⎨⎧​121​(1+cos(πb−ax−a​))0​x\<aa≤x≤bx\>b​(25)  
其中 x∗1​, a,b∈R 且 a\<b。如果能量箱耗尽，控制器不应生成潜在的非无源动作。应通过考虑能量箱的状态和功率变量来相应地校正控制律。为此，我们如下校正方程 (4) 中的调制律：

x˙d​=f′(x)+fn′​(x)(26)  
其中：

{f′(x)=fc​(x)+βr′​(s,pr​)fr​(x)fn′​(x)=βn′​(s,pn​)fn​(x)​(27)  
其中 βr′​(s,pr​) 和 βn′​(s,pn​) 是满足以下条件的标量函数：

βi′​(s,pi​)={1βi​(s,pi​)​if pi​\<0otherwise​i=r,n(28)  
现在让我们定义最终的存储函数 W(x,x˙,s)，考虑能量箱的动力学：

W(x,x˙,s)=21​x˙TM(x)x˙+d1​Vc​(x)+s(29)  
将 s 替换为方程 (23)，将 x˙d​ 替换为方程 (26)， W(x,x˙,s) 的变化率变为：

W˙(x,x˙,s)=(βr′​(s,pr​)−βr​(s,pr​))pr​+(βn′​(s,pn​)−βn​(s,pn​))pn​−(1−α(s))pd​+x˙TFe​(30)  
前两项现在都是非正的，而第三项仍然是耗散的，因为 1−α(s)≥0。因此，整个系统相对于 x˙TFe​ 是无源的。

## **附录 C**

### **无源性分析：双手动任务**

保证双手动系统的无源性是困难的，特别是如果两个机器人的期望动力学都是耦合的。但是，让我们假设期望动力学 x˙dC​ 和 x˙dD​ 都是保守的，使得：

x˙di​=−∇xi​Vi​(xi)i=C,D(31)  
其中 VC​(xC) 和 VD​(xD) 是势函数。为两个机器人设置相同的阻抗增益：d1L​=d1R​=d1​，可以类似地考虑方程 (18) 中的全局存储函数 W(xL,xR,x˙L,x˙R)，其中考虑了两个机器人的动能和势函数：

W(xL,xR,x˙L,x˙R)=21​\[x˙RTBR(xR)x˙R+x˙LTBL(xL)x˙L\]+2d1​VC​(xC)+2d1​​VD​(xD)(32)  
其中 BR(xR) 和 BL(xL) 是机器人的惯性矩阵。  
使用方程 (31) 对方程 (32) 进行微分得到：  
W˙(xL,xR,x˙L,x˙R)=21​dtd​\[x˙RTBR(xR)x˙R+x˙LTBL(xL)x˙L\]−2d1​x˙CTx˙dC​−2d1​​x˙DTx˙dD​(33)  
根据方程 (7) 中 xC 和 xD 的定义，它变为：

W˙(xL,xR,x˙L,x˙R)=21​dtd​\[x˙RTBR(xR)x˙R+x˙LTBL(xL)x˙L\]−d1​(x˙R+x˙L)Tx˙dC​−2d1​​(x˙R−x˙L)Tx˙dD​  
展开机器人动能的时间导数，如方程 (19) 和 (20) 所述，结果是：

W˙(xL,xR,x˙L,x˙R)=x˙RTFcR​+x˙RTFeR​+x˙LTFcL​+x˙LTFeL​−d1​(x˙R+x˙L)Tx˙dC​−2d1​​(x˙R−x˙L)Tx˙dD​  
使用方程 (13) 和 (3) 替换 FcR​ 和 FcL​ 得到：

W˙(xL,xR,x˙L,x˙R)=d1​x˙RTfR(xL,xR)+d1​x˙RTfnR​(xL,xR)+d1​x˙RTx˙dC​−x˙RTDR(xL,xR)x˙R+x˙RTFeR​+d1​x˙LTfL(xL,xR)+d1​x˙LTfnL​(xL,xR)+d1​x˙LTx˙dC​−x˙LTDL(xL,xR)x˙L+x˙LTFeL​−d1​(x˙R+x˙L)Tx˙dC​−2d1​​(x˙R−x˙L)Tx˙dD​  
抵消包含 x˙dC​ 和 x˙dD​ 的项（使用方程 10）最终得到：

W˙(xL,xR,x˙L,x˙R)=W˙R(xL,xR,x˙R)+W˙L(xL,xR,x˙L)  
其中：

W˙i(xL,xR,x˙i)=d1​x˙iTfni​(xL,xR)−x˙iTDi(xL,xR)x˙i+x˙iTFei​  
W˙i(xL,xR,x˙i) 其中 i=L,R 等同于方程 (21)，不包含非保守项。因此，为了保证双手动系统的稳定性，我们可以使用附录 B 中导出的能量箱方法。为此，定义了两个能量箱 sR​ 和 sL​ 以使 W˙R(xL,xR,x˙R) 和 W˙L(xL,xR,x˙L) 相对于 x˙RTFeR​ 和 x˙LTFeL​ 分别无源，通过修改每个机器人的控制律。

## **附录 D**

### **技术细节**

### **A. 抛光实验**

非线性表面（例如有机玻璃板）的轮廓使用高斯核的支撑向量回归 (C-SVR)（C=100，f=0.01, σ=0.20）进行学习，以估计空间中任何位置的到表面的法向距离 Γ(x) 和法向量 n(x)。这些信息是相对于附着在由运动捕捉系统跟踪的木板上的局部框架学习的。

控制策略以 200 Hz 的频率运行（例如，Δt​=0.005 s），并且 DS-阻抗控制器增益 d1​, d2​ 和 d3​ 都设置为 150。这些增益是通过实验选择的，以在跟踪精度和与环境（例如人类）的柔顺交互之间获得最佳权衡。

标称 DS f(x) 定义如下：

f(x)=R(x)n(x)v0​(33)  
其中：

v0​\>0 是标称 DS 的目标速度范数（设置为 0.25 m/s）。

R(x) 是一个旋转矩阵，旨在随着机器人接近接触，逐渐将 n(x) 与切线于表面的圆形运动对齐。这样做的动机是拥有一个速度范数恒定且永不消失的标称 DS。此外，圆形运动是围绕表面上固定吸引子定义的，半径为 0.05 m。

接触中的期望力曲线 Fd​(x) 实现如下：

Fd​(x)=⎩⎨⎧​FT​FT,min​0​μF​≥ϵF​∧Γ(x)≤ϵΓ​μF​\<ϵF​∧Γ(x)≤ϵΓ​otherwise​(34)  
其中：

μF​ 是测量法向力在滑动窗口（设置为 10 个样本）上的平均值，而 ϵF​≥0 是力阈值（设置为 3 N）。

ϵΓ​≥0 是表面位置的容差范围（设置为 0.05 m）。

FT,min​ 是接近接触的目标力（设置为 3 N）。它确保与表面发生接触并有助于减少接触时的冲击。

FT​ 是接触中的目标力。每次机器人与表面接触时，它都会在 10、15 和 20 N 之间取不同的值（参见图 6）。

期望的末端执行器姿态曲线如附录 A 所述导出，方程 (15) 中 κ=5。

基于能量箱的无源性校正用于 sm​=60 J 和 δs​=0.1sm​，假设标称 DS 完全非保守（参见附录 B）。

### **B. 双手动实验**

控制策略以 200 Hz 的频率运行，DS-阻抗控制器增益 d1​、d2​ 和 d3​ 对于两个机器人均设置为 150。

通过将正增益矩阵设置为 AC​=4I3×3​ 和 AD​=2I3×3​，其中 I3×3​ 是单位矩阵，来实现机器人标称和调制后的 DS。  
接触中的期望力曲线 Fd​(xL,xR) 实现如下：  
Fd​(x)={FT​FT,min​​(μFL​≥ϵF​∧μFR​≥ϵF​)∧(eC​≤ϵC​∧eD​≤ϵD​)otherwise​(35)  
其中：

eC​=∣∣xC−xoC​∣∣eD​=(xD−xoD​)T∣∣xoD​∣∣xoD​​(36)  
μFi​ 是机器人 i（i=L,R）在滑动窗口（设置为 10 个样本）上测量的法向力平均值，而 ϵF​≥0 是力阈值（设置为 3 N）。  
FT,min​ 是接近接触抓取的目标力（设置为 3 N）。  
FT​ 是接触中的目标力（设置为 15 N）。

eC​ 和 eD​ 分别表示到物体中心位置和距离向量的误差，而 ϵC​ 和 ϵD​ 是正阈值，分别设置为 0.2 m 和 0.05 m。

使用方程 (14)，为左机器人和右机器人定义了期望的姿态曲线，使得它们的末端执行器方向随着误差 eD​ 的减小分别收敛到 nL 和 nR。因此，方程 (15) 通过将 Γ(x) 替换为 eD​ 并将 κ 设置为 3 进行修改。

基于能量箱的无源性校正对于两个机器人均编码为 sm​=4 J 和 δs​=0.1sm​（参见附录 C 和 B）。