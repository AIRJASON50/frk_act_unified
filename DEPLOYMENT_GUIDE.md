# Franka ACT åˆ†å¸ƒå¼éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æœåŠ¡å™¨ç«¯       â”‚         â”‚   å®¢æˆ·ç«¯         â”‚
â”‚  (GPUè®­ç»ƒæœåŠ¡å™¨) â”‚  <â”€â”€â”€>  â”‚ (æœºå™¨äººæ§åˆ¶ç«¯)   â”‚
â”‚                 â”‚         â”‚                 â”‚
â”‚ â€¢ æ¨¡å‹è®­ç»ƒ       â”‚         â”‚ â€¢ æœºå™¨äººæ§åˆ¶     â”‚
â”‚ â€¢ æ¨¡å‹æ¨ç†       â”‚         â”‚ â€¢ æ•°æ®é‡‡é›†       â”‚
â”‚ â€¢ ç½‘ç»œé€šä¿¡       â”‚         â”‚ â€¢ Flask HTTP     â”‚
â”‚ â€¢ æ•°æ®å­˜å‚¨       â”‚         â”‚ â€¢ ROSæ¥å£        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†‘                           â†‘
    AgentLace                   FrankaACTEnv
     (Port 5555)               (HTTP + ROS)
```

## ğŸ–¥ï¸ æœåŠ¡å™¨ç«¯éƒ¨ç½²

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA RTX 4090 æˆ–æ›´é«˜
- **å†…å­˜**: 32GB+ RAM
- **å­˜å‚¨**: 100GB+ å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: åƒå…†ä»¥å¤ªç½‘

### ç¯å¢ƒé…ç½®
```bash
# 1. å…‹éš†é¡¹ç›®
cd /path/to/projects
git clone [é¡¹ç›®åœ°å€]
cd frk_act_unified

# 2. è¿è¡ŒæœåŠ¡å™¨ç«¯é…ç½®
chmod +x deploy/server_setup.sh
./deploy/server_setup.sh

# 3. æ¿€æ´»æœåŠ¡å™¨ç¯å¢ƒ
source ./activate_server_env.sh

# 4. éªŒè¯ç¯å¢ƒ
python3 -c "import torch; print(f'GPUæ•°é‡: {torch.cuda.device_count()}')"
```

### å¯åŠ¨æœåŠ¡å™¨
```bash
# åŸºç¡€å¯åŠ¨ï¼ˆé»˜è®¤ç«¯å£5555ï¼Œä½¿ç”¨æ‰€æœ‰GPUï¼‰
./start_training_server.sh

# è‡ªå®šä¹‰é…ç½®
./start_training_server.sh 5555 "0,1" models/my_model

# å‚æ•°è¯´æ˜ï¼š
# $1: ç«¯å£å· (é»˜è®¤5555)
# $2: GPUè®¾å¤‡ (é»˜è®¤"0,1,2,3")
# $3: æ¨¡å‹ä¿å­˜ç›®å½• (é»˜è®¤models/franka_act)
```

## ğŸ’» å®¢æˆ·ç«¯éƒ¨ç½²

### ç¡¬ä»¶è¦æ±‚
- **CPU**: Intel i5 æˆ–æ›´é«˜
- **å†…å­˜**: 16GB+ RAM  
- **ç½‘ç»œ**: åƒå…†ä»¥å¤ªç½‘è¿æ¥æœåŠ¡å™¨
- **æœºå™¨äºº**: Franka Emika Panda (ä»¿çœŸæˆ–çœŸå®)

### ç¯å¢ƒé…ç½®
```bash
# 1. å®‰è£…ROS Noetic (Ubuntu 20.04)
sudo apt update
sudo apt install ros-noetic-desktop-full

# 2. å…‹éš†é¡¹ç›®åˆ°å®¢æˆ·ç«¯
cd /path/to/client
git clone [é¡¹ç›®åœ°å€]
cd frk_act_unified

# 3. è¿è¡Œå®¢æˆ·ç«¯é…ç½®
chmod +x deploy/client_setup.sh
./deploy/client_setup.sh

# 4. æ¿€æ´»å®¢æˆ·ç«¯ç¯å¢ƒ
source ./activate_client_env.sh

# 5. éªŒè¯ç¯å¢ƒ
python3 -c "import cv2, numpy; print('å®¢æˆ·ç«¯ç¯å¢ƒæ­£å¸¸')"
```

### å¯åŠ¨å®¢æˆ·ç«¯
```bash
# ä»¿çœŸæ¨¡å¼å¯åŠ¨
./start_franka_client.sh 10.16.49.124 172.16.0.2 sim

# çœŸå®æœºå™¨äººæ¨¡å¼
./start_franka_client.sh 10.16.49.124 172.16.0.2 real

# å‚æ•°è¯´æ˜ï¼š
# $1: æœåŠ¡å™¨IP (è®­ç»ƒæœåŠ¡å™¨åœ°å€)
# $2: æœºå™¨äººIP (ä»¿çœŸé»˜è®¤172.16.0.2)
# $3: æ¨¡å¼ (sim/real)
# $4: ä»»åŠ¡åç§° (å¯é€‰)
```

## ğŸ”§ ç¯å¢ƒå·®å¼‚è¯´æ˜

### æœåŠ¡å™¨ç«¯ç¯å¢ƒ (`aloha`)
- **PyTorch**: 2.0.0 + CUDA 11.8
- **æ— ROS**: çº¯Pythonç¯å¢ƒ
- **GPUæ”¯æŒ**: å¤šGPUè®­ç»ƒ
- **ä¾èµ–**: æ·±åº¦å­¦ä¹  + Webæ¡†æ¶

### å®¢æˆ·ç«¯ç¯å¢ƒ (`franka_client`)  
- **è½»é‡çº§**: æ— PyTorch GPUç‰ˆæœ¬
- **ROSé›†æˆ**: ROS Noetic + Python
- **OpenCV**: CPUç‰ˆæœ¬ï¼Œé¿å…GPUå†²çª
- **ä¾èµ–**: æœºå™¨äººæ§åˆ¶ + é€šä¿¡

## ğŸš¦ å¯åŠ¨æµç¨‹

### 1. æœåŠ¡å™¨ç«¯å¯åŠ¨
```bash
# æ¿€æ´»ç¯å¢ƒ
source ./activate_server_env.sh

# å¯åŠ¨è®­ç»ƒæœåŠ¡å™¨
./start_training_server.sh
# çœ‹åˆ°: "ğŸš€ è®­ç»ƒæœåŠ¡å™¨å¯åŠ¨åœ¨ç«¯å£ 5555"
```

### 2. å®¢æˆ·ç«¯å¯åŠ¨
```bash
# æ¿€æ´»ç¯å¢ƒ  
source ./activate_client_env.sh

# å¯åŠ¨å®¢æˆ·ç«¯ï¼ˆæ›¿æ¢ä¸ºå®é™…æœåŠ¡å™¨IPï¼‰
./start_franka_client.sh 10.16.49.124 172.16.0.2 sim
# çœ‹åˆ°: "ğŸ¤– å®¢æˆ·ç«¯è¿æ¥åˆ°æœåŠ¡å™¨ 10.16.49.124:5555"
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### æœåŠ¡å™¨ç«¯ç›‘æ§
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/server_*.log

# ç›‘æ§GPUä½¿ç”¨
nvidia-smi -l 1

# ç›‘æ§ç½‘ç»œç«¯å£
netstat -tlnp | grep 5555
```

### å®¢æˆ·ç«¯ç›‘æ§
```bash
# æŸ¥çœ‹å®¢æˆ·ç«¯æ—¥å¿—
tail -f logs/client_*.log

# ç›‘æ§ROSèŠ‚ç‚¹
rosnode list
rostopic list

# æ£€æŸ¥FlaskæœåŠ¡å™¨
curl http://localhost:5000/robot_state
```

## ğŸ› æ•…éšœæ’é™¤

### ç½‘ç»œè¿æ¥é—®é¢˜
```bash
# æµ‹è¯•æœåŠ¡å™¨è¿é€šæ€§
ping 10.16.49.124
telnet 10.16.49.124 5555

# æ£€æŸ¥é˜²ç«å¢™
sudo ufw status
sudo ufw allow 5555/tcp
```

### ROSç¯å¢ƒé—®é¢˜
```bash
# é‡æ–°source ROS
source /opt/ros/noetic/setup.bash
export ROS_MASTER_URI=http://localhost:11311

# æ£€æŸ¥ROS master
roscore &
rosnode list
```

### ä¾èµ–é—®é¢˜
```bash
# æœåŠ¡å™¨ç«¯é‡æ–°å®‰è£…
conda activate aloha
pip install --force-reinstall torch torchvision

# å®¢æˆ·ç«¯é‡æ–°å®‰è£…
conda activate franka_client  
pip install --force-reinstall opencv-python-headless
```

## ğŸ“ˆ æ€§èƒ½è°ƒä¼˜

### GPUå†…å­˜ä¼˜åŒ–
```bash
# é™åˆ¶GPUå†…å­˜ä½¿ç”¨
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# ä½¿ç”¨æŒ‡å®šGPU
export CUDA_VISIBLE_DEVICES=0,1
```

### ç½‘ç»œä¼˜åŒ–
```bash
# è°ƒæ•´ç½‘ç»œç¼“å†²åŒº
echo 'net.core.rmem_max = 268435456' | sudo tee -a /etc/sysctl.conf
echo 'net.core.wmem_max = 268435456' | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

## ğŸ”„ æ›´æ–°å’Œç»´æŠ¤

### æ›´æ–°é¡¹ç›®ä»£ç 
```bash
# æœåŠ¡å™¨ç«¯æ›´æ–°
git pull origin main
git submodule update --recursive

# å®¢æˆ·ç«¯æ›´æ–°  
git pull origin main
git submodule update --recursive
```

### æ¸…ç†å’Œé‡ç½®
```bash
# æ¸…ç†æ—¥å¿—
rm -f logs/*.log

# é‡ç½®æ¨¡å‹
rm -rf models/franka_act/*

# é‡å¯æ‰€æœ‰æœåŠ¡
pkill -f "train_act_distributed"
pkill -f "franka_server"
```
