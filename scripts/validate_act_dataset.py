#!/usr/bin/env python3

"""
ACT Dataset Validation Tool

MAIN FUNCTIONALITY:
ACTæ•°æ®é›†å…¼å®¹æ€§éªŒè¯å·¥å…·ï¼Œæ£€æŸ¥ç”Ÿæˆçš„HDF5æ–‡ä»¶æ ¼å¼å’Œæ•°æ®å®Œæ•´æ€§

VALIDATION STATES:
1. FILE_DISCOVERY - æ‰«ææŒ‡å®šç›®å½•ï¼Œå‘ç°æ‰€æœ‰HDF5æ–‡ä»¶
2. STRUCTURE_CHECK - éªŒè¯HDF5æ–‡ä»¶å†…éƒ¨ç»“æ„å’Œå¿…éœ€å­—æ®µ
3. DATA_VALIDATION - æ£€æŸ¥æ•°æ®ç»´åº¦ã€ç±»å‹å’Œæ•°å€¼èŒƒå›´
4. COMPATIBILITY_TEST - ç¡®è®¤ACTè®­ç»ƒæ¡†æ¶å…¼å®¹æ€§
5. REPORT_GENERATION - ç”ŸæˆéªŒè¯ç»“æœæŠ¥å‘Š

STATE TRANSITION CONDITIONS:
- FILE_DISCOVERY â†’ STRUCTURE_CHECK: æ‰¾åˆ°è‡³å°‘1ä¸ª.hdf5æ–‡ä»¶
- STRUCTURE_CHECK â†’ DATA_VALIDATION: æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
- DATA_VALIDATION â†’ COMPATIBILITY_TEST: æ•°æ®ç»´åº¦å’Œæ•°å€¼èŒƒå›´æ£€æŸ¥é€šè¿‡
- COMPATIBILITY_TEST â†’ REPORT_GENERATION: å…¼å®¹æ€§æµ‹è¯•å®Œæˆ
- ANY_STATE â†’ ERROR: æ–‡ä»¶æŸåã€æƒé™é”™è¯¯æˆ–æ ¼å¼ä¸å…¼å®¹

VALIDATION CRITERIA:
Required HDF5 Structure:
- Root attributes: 'sim' (simulation flag)
- observations/qpos: (T, 8) float64 - joint positions
- observations/qvel: (T, 8) float64 - joint velocities  
- observations/images/top: (T, H, W, 3) uint8 - RGB images
- action: (T, 8) float64 - target actions

Data Consistency Checks:
- æ‰€æœ‰æ•°æ®é›†é•¿åº¦å¿…é¡»ä¸€è‡´ (Tç»´åº¦ç›¸åŒ)
- å…³èŠ‚æ•°æ®: 8ç»´åº¦ (7ä¸ªå…³èŠ‚ + 1ä¸ªå¤¹çˆª)
- å›¾åƒæ•°æ®: æ ‡å‡†å°ºå¯¸ (é€šå¸¸480x640x3)
- æ•°å€¼èŒƒå›´: å…³èŠ‚ä½ç½®[-Ï€,Ï€], é€Ÿåº¦åˆç†èŒƒå›´
- NaN/Infæ£€æµ‹: ä¸å…è®¸æ— æ•ˆæ•°å€¼

ERROR DETECTION:
- Missing fields: ç¼ºå°‘å¿…éœ€çš„æ•°æ®é›†æˆ–å±æ€§
- Dimension mismatch: æ•°æ®ç»´åº¦ä¸åŒ¹é…
- Data corruption: æ–‡ä»¶æŸåæˆ–è¯»å–é”™è¯¯
- Type errors: æ•°æ®ç±»å‹ä¸æ­£ç¡®
- Range violations: æ•°å€¼è¶…å‡ºåˆç†èŒƒå›´

COMPATIBILITY VERIFICATION:
- ACT training pipeline compatibility
- Standard ML framework support (PyTorch/JAX)
- Episode length consistency across dataset
- Memory usage estimation for training

OUTPUT REPORTING:
- File-by-file validation summary
- Overall dataset statistics
- Compatibility status (âœ…/âŒ)
- Detailed error messages and suggestions
- Training readiness assessment

USAGE:
python3 validate_act_dataset.py <dataset_directory>
"""

import h5py
import numpy as np
import os
import sys

def validate_hdf5_structure(filepath):
    """Validate HDF5 file structure matches ACT requirements"""
    print(f"Validating: {filepath}")
    
    try:
        with h5py.File(filepath, 'r') as f:
            # Check required attributes
            if 'sim' not in f.attrs:
                print("âŒ Missing 'sim' attribute")
                return False
            print(f"âœ… sim attribute: {f.attrs['sim']}")
            
            # Check observations group
            if 'observations' not in f:
                print("âŒ Missing 'observations' group")
                return False
            
            obs = f['observations']
            
            # Check qpos dataset
            if 'qpos' not in obs:
                print("âŒ Missing 'qpos' dataset")
                return False
            qpos = obs['qpos']
            print(f"âœ… qpos shape: {qpos.shape}, dtype: {qpos.dtype}")
            
            # Check qvel dataset  
            if 'qvel' not in obs:
                print("âŒ Missing 'qvel' dataset")
                return False
            qvel = obs['qvel']
            print(f"âœ… qvel shape: {qvel.shape}, dtype: {qvel.dtype}")
            
            # Check images group
            if 'images' not in obs:
                print("âŒ Missing 'images' group")
                return False
            
            images = obs['images']
            if 'top' not in images:
                print("âŒ Missing 'top' camera images")
                return False
            
            top_imgs = images['top']
            print(f"âœ… top images shape: {top_imgs.shape}, dtype: {top_imgs.dtype}")
            
            # Check action dataset
            if 'action' not in f:
                print("âŒ Missing 'action' dataset")
                return False
            action = f['action']
            print(f"âœ… action shape: {action.shape}, dtype: {action.dtype}")
            
            # Validate data consistency
            T = qpos.shape[0]
            if qvel.shape[0] != T:
                print(f"âŒ qvel length {qvel.shape[0]} != qpos length {T}")
                return False
            
            if action.shape[0] != T:
                print(f"âŒ action length {action.shape[0]} != qpos length {T}")
                return False
                
            if top_imgs.shape[0] != T:
                print(f"âŒ images length {top_imgs.shape[0]} != qpos length {T}")
                return False
            
            print(f"âœ… All datasets have consistent length: {T}")
            
            # Validate dimensions
            if len(qpos.shape) != 2:
                print(f"âŒ qpos should be 2D, got {len(qpos.shape)}D")
                return False
                
            if qpos.shape[1] != 8:  # 7 joints + 1 gripper for single arm
                print(f"âŒ qpos should have 8 DOF, got {qpos.shape[1]}")
                return False
                
            if len(top_imgs.shape) != 4:  # (T, H, W, C)
                print(f"âŒ images should be 4D (T,H,W,C), got {len(top_imgs.shape)}D")
                return False
                
            print("âœ… All dimensions are correct")
            
            # Sample some data
            print("\nğŸ“Š Sample data:")
            print(f"qpos[0]: {qpos[0][:3]}...")  # First 3 joint positions
            print(f"qvel[0]: {qvel[0][:3]}...")  # First 3 joint velocities  
            print(f"action[0]: {action[0][:3]}...")  # First 3 action values
            print(f"image[0] shape: {top_imgs[0].shape}, min: {top_imgs[0].min()}, max: {top_imgs[0].max()}")
            
            return True
            
    except Exception as e:
        print(f"âŒ Error reading file: {e}")
        return False

def main():
    """Main validation function"""
    print("ğŸ” ACT Dataset Validation Tool")
    print("=" * 50)
    
    # Check for dataset files
    dataset_dir = "/home/jason/ws/catkin_ws/src/act_data"
    
    if not os.path.exists(dataset_dir):
        print(f"âŒ Dataset directory not found: {dataset_dir}")
        return False
    
    # Find HDF5 files
    hdf5_files = [f for f in os.listdir(dataset_dir) if f.endswith('.hdf5')]
    
    if not hdf5_files:
        print(f"âŒ No HDF5 files found in {dataset_dir}")
        return False
    
    print(f"Found {len(hdf5_files)} HDF5 files:")
    for f in hdf5_files:
        print(f"  - {f}")
    
    print("\n" + "=" * 50)
    
    # Validate each file
    all_valid = True
    for filename in hdf5_files:
        filepath = os.path.join(dataset_dir, filename)
        is_valid = validate_hdf5_structure(filepath)
        all_valid = all_valid and is_valid
        print("-" * 30)
    
    if all_valid:
        print("ğŸ‰ All dataset files are ACT-compatible!")
        return True
    else:
        print("âš ï¸  Some files have issues")
        return False

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
