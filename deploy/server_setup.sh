#!/bin/bash
# deploy/server_setup.sh
# Franka ACT æœåŠ¡å™¨ç«¯ç¯å¢ƒé…ç½®è„šæœ¬
# é€‚ç”¨äºGPUè®­ç»ƒæœåŠ¡å™¨ï¼Œæ— éœ€ROSç¯å¢ƒ

set -e

echo "========================================="
echo "Franka ACT æœåŠ¡å™¨ç«¯ç¯å¢ƒé…ç½®"
echo "========================================="

# æ£€æŸ¥condaç¯å¢ƒ
if ! command -v conda &> /dev/null; then
    echo "âŒ Condaæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Minicondaæˆ–Anaconda"
    exit 1
fi

# æ¿€æ´»æˆ–åˆ›å»ºalohaç¯å¢ƒ
echo "ğŸ”§ é…ç½®Pythonç¯å¢ƒ..."
source $HOME/miniconda3/etc/profile.d/conda.sh
if ! conda env list | grep -q "aloha"; then
    echo "åˆ›å»ºaloha condaç¯å¢ƒ..."
    conda create -n aloha python=3.9 -y
fi

conda activate aloha

# æœåŠ¡å™¨ç«¯ä¾èµ–å®‰è£…
echo "ğŸ“¦ å®‰è£…æœåŠ¡å™¨ç«¯Pythonä¾èµ–..."
pip install --upgrade pip

# æ·±åº¦å­¦ä¹ æ¡†æ¶
pip install torch==2.0.0 torchvision==0.15.0 --index-url https://download.pytorch.org/whl/cu118

# åŸºç¡€ç§‘å­¦è®¡ç®—åŒ…
pip install numpy==1.24.3 scipy matplotlib seaborn
pip install gymnasium==1.1.1 opencv-python-headless
pip install pillow>=8.0.0 imageio

# Webæ¡†æ¶å’Œç½‘ç»œé€šä¿¡
pip install flask==2.3.2 requests==2.31.0
pip install websockets aiohttp

# é…ç½®æ–‡ä»¶å’Œæ•°æ®å¤„ç†
pip install pyyaml>=6.0 h5py wandb
pip install tqdm ipython

# æ¨¡å‹ç›¸å…³ä¾èµ–
pip install transformers==4.30.0
pip install einops timm

echo "ğŸ§ª éªŒè¯æœåŠ¡å™¨ç«¯ç¯å¢ƒ..."
python3 -c "
import torch
print(f'âœ“ PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'âœ“ CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ“ GPUæ•°é‡: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'  - GPU{i}: {torch.cuda.get_device_name(i)}')

import numpy as np
print(f'âœ“ NumPyç‰ˆæœ¬: {np.__version__}')

import yaml, flask
print('âœ“ é…ç½®å’ŒWebæ¡†æ¶å¯¼å…¥æˆåŠŸ')
"

# åˆ›å»ºæœåŠ¡å™¨ç«¯ç¯å¢ƒæ¿€æ´»è„šæœ¬
echo "ğŸ“„ åˆ›å»ºæœåŠ¡å™¨ç«¯ç¯å¢ƒè„šæœ¬..."
cat > activate_server_env.sh << 'EOF'
#!/bin/bash
# æœåŠ¡å™¨ç«¯ç¯å¢ƒæ¿€æ´»è„šæœ¬

source $HOME/miniconda3/etc/profile.d/conda.sh
conda activate aloha

export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-"0,1,2,3"}
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

export FRANKA_ACT_ROOT=$(pwd)
export PYTHONPATH=$FRANKA_ACT_ROOT:$FRANKA_ACT_ROOT/act_algo:$PYTHONPATH

echo "ğŸ–¥ï¸  æœåŠ¡å™¨ç«¯ç¯å¢ƒå·²æ¿€æ´»"
echo "   - Condaç¯å¢ƒ: aloha"
echo "   - CUDAè®¾å¤‡: $CUDA_VISIBLE_DEVICES"
echo "   - é¡¹ç›®æ ¹ç›®å½•: $FRANKA_ACT_ROOT"
echo "   - PyTorchç‰ˆæœ¬: $(python -c 'import torch; print(torch.__version__)')"
EOF

chmod +x activate_server_env.sh

# åˆ›å»ºæœåŠ¡å™¨å¯åŠ¨è„šæœ¬
echo "ğŸš€ é…ç½®æœåŠ¡å™¨å¯åŠ¨è„šæœ¬..."
cat > start_training_server.sh << 'EOF'
#!/bin/bash
# æœåŠ¡å™¨ç«¯è®­ç»ƒå¯åŠ¨è„šæœ¬

set -e

# å‚æ•°è®¾ç½®
PORT=${1:-5555}
GPUS=${2:-"0,1,2,3"}
CKPT_DIR=${3:-"models/franka_act"}
CONFIG=${4:-"configs/act_config.yaml"}

echo "========================================="
echo "å¯åŠ¨ Franka ACT è®­ç»ƒæœåŠ¡å™¨"
echo "ç«¯å£: $PORT"
echo "GPUè®¾å¤‡: $GPUS"
echo "æ¨¡å‹ç›®å½•: $CKPT_DIR"
echo "é…ç½®æ–‡ä»¶: $CONFIG"
echo "========================================="

# æ¿€æ´»ç¯å¢ƒ
source ./activate_server_env.sh

# è®¾ç½®GPU
export CUDA_VISIBLE_DEVICES=$GPUS

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p $CKPT_DIR
mkdir -p logs

# å¯åŠ¨è®­ç»ƒæœåŠ¡å™¨
echo "ğŸš€ å¯åŠ¨è®­ç»ƒæœåŠ¡å™¨..."
python3 train_act_distributed.py \
    --mode server \
    --port $PORT \
    --config $CONFIG \
    --ckpt_dir $CKPT_DIR \
    --log_dir logs \
    2>&1 | tee logs/server_$(date +%Y%m%d_%H%M%S).log

EOF

chmod +x start_training_server.sh

echo "âœ… æœåŠ¡å™¨ç«¯ç¯å¢ƒé…ç½®å®Œæˆï¼"
echo ""
echo "ä½¿ç”¨æ–¹æ³•ï¼š"
echo "1. æ¿€æ´»ç¯å¢ƒ: source ./activate_server_env.sh"
echo "2. å¯åŠ¨è®­ç»ƒ: ./start_training_server.sh [ç«¯å£] [GPU] [æ¨¡å‹ç›®å½•]"
echo ""
