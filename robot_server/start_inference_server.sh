#!/bin/bash

#===============================================================================
# ACTåˆ†å¸ƒå¼æ¨ç†æœåŠ¡å™¨å¯åŠ¨è„šæœ¬ - åŸºäºAgentLaceåè®®
#
# ä½¿ç”¨æ–¹æ³•:
# ./start_inference_server.sh                    # é»˜è®¤é…ç½®å¯åŠ¨
# ./start_inference_server.sh 5556              # æŒ‡å®šç«¯å£
# ./start_inference_server.sh 5555 /path/model  # æŒ‡å®šç«¯å£å’Œæ¨¡å‹è·¯å¾„
#===============================================================================

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# å‚æ•°è§£æ
PORT=${1:-5555}
MODEL_PATH=${2:-"/home/wujielin/CascadeProjects/data/act_training/checkpoints/franka_pick_place"}
LOG_LEVEL=${3:-"INFO"}

echo -e "${BLUE}========================================${NC}"
echo -e "${BLUE}   ACTåˆ†å¸ƒå¼æ¨ç†æœåŠ¡å™¨ v2.0${NC}"
echo -e "${BLUE}   åè®®: AgentLace + RTX 4090ä¼˜åŒ–${NC}"
echo -e "${BLUE}========================================${NC}"
echo ""

# ç¯å¢ƒæ£€æŸ¥å’Œæ¿€æ´»
echo -e "${BLUE}ğŸ”§ ç¯å¢ƒæ£€æŸ¥...${NC}"

# æ£€æŸ¥condaç¯å¢ƒ
if [[ "$CONDA_DEFAULT_ENV" != "aloha" ]]; then
    echo -e "${YELLOW}âš ï¸ æ£€æµ‹åˆ°æœªæ¿€æ´»alohaç¯å¢ƒï¼Œæ­£åœ¨æ¿€æ´»...${NC}"
    source ~/miniconda3/etc/profile.d/conda.sh
    conda activate aloha
    if [[ "$CONDA_DEFAULT_ENV" != "aloha" ]]; then
        echo -e "${RED}âŒ æ— æ³•æ¿€æ´»alohaç¯å¢ƒï¼Œè¯·æ‰‹åŠ¨æ¿€æ´»åé‡è¯•${NC}"
        exit 1
    fi
fi

echo -e "${GREEN}âœ… Condaç¯å¢ƒ: $CONDA_DEFAULT_ENV${NC}"

# è®¾ç½®AgentLaceç¯å¢ƒå˜é‡
export ACT_SERVER_IP="10.16.49.124"
export ACT_SERVER_PORT="$PORT"
export CUDA_VISIBLE_DEVICES="0"
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:1024"

# æ£€æŸ¥GPUçŠ¶æ€
if command -v nvidia-smi &> /dev/null; then
    echo -e "${GREEN}ğŸš€ GPUçŠ¶æ€:${NC}"
    GPU_INFO=$(nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits | head -1)
    echo "   $GPU_INFO"
    
    # æ£€æŸ¥GPUå†…å­˜
    FREE_MEM=$(echo $GPU_INFO | cut -d',' -f3 | tr -d ' ')
    if [[ $FREE_MEM -lt 8000 ]]; then
        echo -e "${YELLOW}âš ï¸ GPUå¯ç”¨å†…å­˜è¾ƒå°‘: ${FREE_MEM}MB < 8GB${NC}"
    fi
else
    echo -e "${YELLOW}âš ï¸ æœªæ£€æµ‹åˆ°NVIDIA GPUï¼Œå°†ä½¿ç”¨CPUæ¨ç†${NC}"
fi

echo ""
echo -e "${BLUE}ğŸ“‹ æœåŠ¡å™¨é…ç½®:${NC}"
echo "   åè®®: AgentLace v0.0.2"
echo "   æœåŠ¡å™¨IP: $ACT_SERVER_IP"
echo "   ç›‘å¬ç«¯å£: $PORT (REQ-REP)"
echo "   å¹¿æ’­ç«¯å£: $((PORT + 1)) (PUB-SUB)"
echo "   æ¨¡å‹è·¯å¾„: $MODEL_PATH"
echo "   æ—¥å¿—çº§åˆ«: $LOG_LEVEL"
echo "   GPUä¼˜åŒ–: RTX 4090ä¸“ç”¨é…ç½®"
echo ""

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
echo -e "${BLUE}ğŸ” æ¨¡å‹æ–‡ä»¶æ£€æŸ¥...${NC}"
if [[ ! -d "$MODEL_PATH" ]]; then
    echo -e "${RED}âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: $MODEL_PATH${NC}"
    echo "è¯·ç¡®è®¤æ¨¡å‹å·²è®­ç»ƒå®Œæˆ"
    exit 1
fi

MODEL_FILES=$(find "$MODEL_PATH" -name "policy_epoch_*.ckpt" | wc -l)
if [[ $MODEL_FILES -eq 0 ]]; then
    echo -e "${RED}âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶${NC}"
    exit 1
fi

LATEST_MODEL=$(find "$MODEL_PATH" -name "policy_epoch_*.ckpt" | sort -V | tail -1)
echo -e "${GREEN}âœ… æ‰¾åˆ° $MODEL_FILES ä¸ªæ¨¡å‹æ–‡ä»¶${NC}"
echo -e "${GREEN}âœ… ä½¿ç”¨æœ€æ–°æ¨¡å‹: $(basename "$LATEST_MODEL")${NC}"

# æ£€æŸ¥AgentLaceä¾èµ–
echo ""
echo -e "${BLUE}ğŸ”— AgentLaceä¾èµ–æ£€æŸ¥...${NC}"
python -c "
try:
    import zmq
    print('âœ… ZeroMQç‰ˆæœ¬:', zmq.zmq_version())
    
    import sys
    sys.path.append('communication/agentlace')
    from agentlace.trainer import TrainerServer
    print('âœ… AgentLaceåè®®å°±ç»ª')
    
    import torch
    print('âœ… PyTorchç‰ˆæœ¬:', torch.__version__)
    print('âœ… CUDAå¯ç”¨:', torch.cuda.is_available())
    
except ImportError as e:
    print('âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥:', e)
    exit(1)
"

if [[ $? -ne 0 ]]; then
    echo -e "${RED}âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·è¿è¡Œ communication/server_setup.sh${NC}"
    exit 1
fi

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

echo ""
echo -e "${BLUE}ğŸš€ å¯åŠ¨ACTåˆ†å¸ƒå¼æ¨ç†æœåŠ¡å™¨...${NC}"
echo -e "${YELLOW}ä½¿ç”¨ Ctrl+C åœæ­¢æœåŠ¡å™¨${NC}"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# å¯åŠ¨æœåŠ¡å™¨
cd communication/
python act_server.py \
    --port "$PORT" \
    --model_path "$MODEL_PATH" \
    --log_level "$LOG_LEVEL" \
    2>&1 | tee ../logs/inference_server_$(date +%Y%m%d_%H%M%S).log

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo -e "${BLUE}    ACTæ¨ç†æœåŠ¡å™¨å·²åœæ­¢${NC}"
echo -e "${BLUE}========================================${NC}"
