#!/usr/bin/env python3
"""
ACTåˆ†å¸ƒå¼æ¨ç†æœåŠ¡å™¨AgentLaceå»¶è¿Ÿæµ‹è¯•
éªŒè¯AgentLaceåè®®æ˜¯å¦æ­£å¸¸éƒ¨ç½²å¹¶æµ‹é‡ç½‘ç»œå»¶è¿Ÿ
"""

import sys
import time
import numpy as np
import base64
import cv2
import statistics
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ è·¯å¾„
current_dir = Path(__file__).parent
communication_dir = current_dir.parent / "communication"
sys.path.append(str(communication_dir))
sys.path.append(str(communication_dir / "agentlace"))

# å¯¼å…¥AgentLace
try:
    from agentlace.trainer import TrainerClient, TrainerConfig
    print("âœ… AgentLaceå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ AgentLaceå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·è¿è¡Œ: pip install -e communication/agentlace")
    sys.exit(1)

def test_agentlace_connection():
    """æµ‹è¯•AgentLaceåè®®è¿æ¥"""
    print("ğŸ”— æµ‹è¯•AgentLaceåè®®è¿æ¥...")
    
    try:
        # åˆ›å»ºé…ç½®
        config = TrainerConfig(
            port_number=5555,
            broadcast_port=5556,
            request_types=["inference", "server_status"],
            rate_limit=1000,
            version="0.0.2"
        )
        
        # åˆ›å»ºå®¢æˆ·ç«¯ (ä½¿ç”¨æœ¬åœ°ç¯å›åœ°å€è¿›è¡Œå•æœºæµ‹è¯•)
        client = TrainerClient("test_client", "127.0.0.1", config)
        print("âœ… AgentLaceå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å¤šæ¬¡è¿æ¥å»¶è¿Ÿ
        latencies = []
        for i in range(5):
            start_time = time.time()
            response = client.request("server_status", {})
            latency = (time.time() - start_time) * 1000
            latencies.append(latency)
            
            if response and response.get("success"):
                print(f"   æµ‹è¯• {i+1}/5: {latency:.2f}ms")
            else:
                print(f"   æµ‹è¯• {i+1}/5: å¤±è´¥")
                return False, []
            
            time.sleep(0.1)  # çŸ­æš‚é—´éš”
        
        # è®¡ç®—å»¶è¿Ÿç»Ÿè®¡
        avg_latency = statistics.mean(latencies)
        min_latency = min(latencies)
        max_latency = max(latencies)
        
        print(f"âœ… AgentLaceè¿æ¥æµ‹è¯•æˆåŠŸ:")
        print(f"   å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"   æœ€å°å»¶è¿Ÿ: {min_latency:.2f}ms")
        print(f"   æœ€å¤§å»¶è¿Ÿ: {max_latency:.2f}ms")
        print(f"   å»¶è¿ŸæŠ–åŠ¨: {max_latency - min_latency:.2f}ms")
        
        return True, latencies
            
    except Exception as e:
        print(f"âŒ AgentLaceè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, []

def test_inference_latency():
    """æµ‹è¯•æ¨ç†è¯·æ±‚å»¶è¿Ÿ"""
    print("ğŸ¯ æµ‹è¯•æ¨ç†å»¶è¿Ÿæ€§èƒ½...")
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        config = TrainerConfig(
            port_number=5555,
            broadcast_port=5556,
            request_types=["inference", "server_status"],
            rate_limit=1000,
            version="0.0.2"
        )
        client = TrainerClient("inference_test_client", "127.0.0.1", config)
        
        # æµ‹è¯•ä¸åŒå¤§å°çš„å›¾åƒå»¶è¿Ÿ
        image_sizes = [
            (240, 320, "å°å›¾åƒ"),
            (480, 640, "æ ‡å‡†å›¾åƒ"),
        ]
        
        for height, width, desc in image_sizes:
            print(f"\nğŸ“Š {desc} ({height}Ã—{width}) å»¶è¿Ÿæµ‹è¯•:")
            
            latencies = []
            for i in range(3):
                # åˆ›å»ºæµ‹è¯•æ•°æ®
                qpos = np.random.randn(8).astype(np.float32) * 0.1
                image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)
                
                # ç¼–ç å›¾åƒä¸ºJPEG
                _, buffer = cv2.imencode('.jpg', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
                image_b64 = base64.b64encode(buffer).decode('utf-8')
                
                # æ„å»ºæ¨ç†è¯·æ±‚
                payload = {
                    "qpos": qpos.tolist(),
                    "qvel": [0.0] * 8,
                    "image": image_b64,
                    "timestamp": time.time(),
                    "request_id": f"latency_test_{i}"
                }
                
                # æµ‹é‡å»¶è¿Ÿ
                start_time = time.time()
                response = client.request("inference", payload)
                network_latency = (time.time() - start_time) * 1000
                latencies.append(network_latency)
                
                if response and response.get("success"):
                    print(f"   æµ‹è¯• {i+1}/3: ç½‘ç»œ{network_latency:.1f}ms + æ¨ç†{response.get('inference_ms', 0):.1f}ms = æ€»è®¡{response.get('latency_ms', 0):.1f}ms")
                    print(f"            å›¾åƒå¤§å°: {len(image_b64)} bytes")
                else:
                    print(f"   æµ‹è¯• {i+1}/3: å¤±è´¥ - {response}")
                    return False
                
                time.sleep(0.2)
            
            # å»¶è¿Ÿç»Ÿè®¡
            avg_latency = statistics.mean(latencies)
            print(f"   å¹³å‡ç½‘ç»œå»¶è¿Ÿ: {avg_latency:.2f}ms")
        
        return True
            
    except Exception as e:
        print(f"âŒ å»¶è¿Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ACTåˆ†å¸ƒå¼æ¨ç†æœåŠ¡å™¨ AgentLace æµ‹è¯•")
    print("=" * 60)
    
    print("ğŸ“‹ æµ‹è¯•å†…å®¹:")
    print("   1. AgentLaceåè®®è¿æ¥æµ‹è¯•")
    print("   2. ç½‘ç»œå»¶è¿Ÿæ€§èƒ½æµ‹è¯•")
    print("   3. æ¨ç†åŠŸèƒ½å»¶è¿Ÿæµ‹è¯•")
    print("")
    print("âš ï¸ è¯·ç¡®ä¿æœåŠ¡å™¨å·²å¯åŠ¨:")
    print("   cd robot_server && ./start_inference_server.sh")
    print("")
    
    input("æŒ‰å›è½¦é”®å¼€å§‹æµ‹è¯•...")
    print("")
    
    # æµ‹è¯•AgentLaceè¿æ¥
    print("ğŸ”— ç¬¬ä¸€é˜¶æ®µ: AgentLaceåè®®æµ‹è¯•")
    connection_ok, latencies = test_agentlace_connection()
    print("")
    
    if connection_ok:
        # æµ‹è¯•æ¨ç†å»¶è¿Ÿ
        print("âš¡ ç¬¬äºŒé˜¶æ®µ: æ¨ç†å»¶è¿Ÿæµ‹è¯•")
        inference_ok = test_inference_latency()
        print("")
        
        # å»¶è¿Ÿåˆ†æ
        if latencies:
            avg_latency = statistics.mean(latencies)
            print("ğŸ“Š å»¶è¿Ÿåˆ†ææŠ¥å‘Š:")
            print(f"   AgentLaceå¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
            
            if avg_latency < 20:
                print("   âœ… å»¶è¿Ÿä¼˜ç§€ (<20ms) - é€‚åˆå®æ—¶æ§åˆ¶")
            elif avg_latency < 50:
                print("   âœ… å»¶è¿Ÿè‰¯å¥½ (<50ms) - é€‚åˆACTæ‰¹é‡é¢„æµ‹")
            else:
                print("   âš ï¸ å»¶è¿Ÿè¾ƒé«˜ (>50ms) - å¯èƒ½å½±å“å®æ—¶æ€§")
        
        # æ€»ç»“
        print("")
        print("=" * 60)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“:")
        print(f"   AgentLaceè¿æ¥: {'âœ… æˆåŠŸ' if connection_ok else 'âŒ å¤±è´¥'}")
        print(f"   æ¨ç†åŠŸèƒ½: {'âœ… æˆåŠŸ' if inference_ok else 'âŒ å¤±è´¥'}")
        
        if connection_ok and inference_ok:
            print("")
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AgentLaceæ¨ç†æœåŠ¡å™¨å·¥ä½œæ­£å¸¸ï¼")
            print("ğŸ’¡ ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å®¢æˆ·ç«¯å¼€å‘")
        else:
            print("")
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨é…ç½®")
    else:
        print("âŒ AgentLaceè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥:")
        print("   1. æœåŠ¡å™¨æ˜¯å¦å·²å¯åŠ¨ (./start_inference_server.sh)")
        print("   2. ç«¯å£5555æ˜¯å¦å¯ç”¨ (netstat -an | grep 5555)")
        print("   3. é˜²ç«å¢™è®¾ç½®")
        print("   4. AgentLaceä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")

if __name__ == "__main__":
    main()
