#!/usr/bin/env python3
"""
Franka ACTæ¨¡å‹éªŒè¯è„šæœ¬
éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¡®å¤„ç†Frankaæ•°æ®æµ
"""

import torch
import sys
import os
import argparse
import numpy as np
import h5py
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def model_validate(ckpt_path):
    """éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨"""
    print(f"ğŸ” éªŒè¯æ¨¡å‹: {ckpt_path}")
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(ckpt_path, map_location='cpu')
        
        print(f"âœ… æ¨¡å‹æ£€æŸ¥ç‚¹ä¿¡æ¯:")
        print(f"   Epoch: {checkpoint.get('epoch', 'Unknown')}")
        print(f"   Loss: {checkpoint.get('min_val_loss', 'Unknown')}")
        
        # æ£€æŸ¥æ¨¡å‹å‚æ•°
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            total_params = sum(p.numel() for p in state_dict.values())
            print(f"   å‚æ•°æ•°é‡: {total_params/1e6:.2f}M")
            
            # æ£€æŸ¥å…³é”®å±‚
            key_layers = ['action_head.weight', 'input_proj_robot_state.weight']
            for layer in key_layers:
                if layer in state_dict:
                    shape = state_dict[layer].shape
                    print(f"   {layer}: {shape}")
        
        print("âœ… æ¨¡å‹æ£€æŸ¥ç‚¹éªŒè¯é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ£€æŸ¥ç‚¹éªŒè¯å¤±è´¥: {e}")
        return False

def validate_franka_compatibility(ckpt_path):
    """éªŒè¯æ¨¡å‹æ˜¯å¦ä¸Frankaæ•°æ®æµå…¼å®¹"""
    print(f"\nğŸ¤– éªŒè¯Frankaå…¼å®¹æ€§...")
    
    try:
        from act_algo_train.policy import ACTPolicy
        from act_algo_train.franka_constants import STATE_DIM, ACTION_DIM, CHUNK_SIZE
        
        # åˆ›å»ºFrankaå…¼å®¹çš„é…ç½®
        config = {
            'lr': 1e-5,
            'num_queries': CHUNK_SIZE,  # 100
            'kl_weight': 10,
            'hidden_dim': 512,
            'dim_feedforward': 3200,
            'lr_backbone': 1e-5,
            'backbone': 'resnet18',
            'enc_layers': 4,
            'dec_layers': 7,
            'nheads': 8,
            'camera_names': ['top']
        }
        
        print(f"ğŸ“Š Frankaé…ç½®æ£€æŸ¥:")
        print(f"   çŠ¶æ€ç»´åº¦: {STATE_DIM} (7å…³èŠ‚+1å¤¹çˆª)")
        print(f"   åŠ¨ä½œç»´åº¦: {ACTION_DIM}")
        print(f"   Chunkå¤§å°: {CHUNK_SIZE}")
        print(f"   ç›¸æœº: {config['camera_names']}")
        
        # åŠ è½½æ¨¡å‹
        policy = ACTPolicy(config)
        checkpoint = torch.load(ckpt_path, map_location='cpu')
        
        # æ£€æŸ¥checkpointæ ¼å¼å¹¶åŠ è½½
        if 'model_state_dict' in checkpoint:
            policy.load_state_dict(checkpoint['model_state_dict'])
        else:
            # ç›´æ¥æ˜¯æ¨¡å‹æƒé‡
            policy.load_state_dict(checkpoint)
        policy.eval()
        
        # æ£€æŸ¥è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆ›å»ºFrankaæ ¼å¼çš„æµ‹è¯•æ•°æ®
        batch_size = 1
        qpos = torch.randn(batch_size, STATE_DIM).to(device)  # 8ç»´çŠ¶æ€
        image = torch.randn(batch_size, 1, 3, 480, 640).to(device)  # å•ç›¸æœºRGBå›¾åƒ
        
        print(f"ğŸ§ª æµ‹è¯•æ•°æ®æ ¼å¼:")
        print(f"   qposå½¢çŠ¶: {qpos.shape} (æœŸæœ›: [1, 8])")
        print(f"   imageå½¢çŠ¶: {image.shape} (æœŸæœ›: [1, 1, 3, 480, 640])")
        
        # æµ‹è¯•æ¨ç†
        with torch.no_grad():
            actions = policy(qpos, image)
        
        print(f"âœ… æ¨ç†æµ‹è¯•æˆåŠŸ!")
        print(f"   è¾“å‡ºåŠ¨ä½œå½¢çŠ¶: {actions.shape} (æœŸæœ›: [1, 100, 8])")
        
        # éªŒè¯è¾“å‡ºç»´åº¦
        expected_shape = (batch_size, CHUNK_SIZE, ACTION_DIM)
        if actions.shape == expected_shape:
            print(f"âœ… è¾“å‡ºç»´åº¦æ­£ç¡®: {actions.shape}")
        else:
            print(f"âŒ è¾“å‡ºç»´åº¦é”™è¯¯: æœŸæœ›{expected_shape}, å®é™…{actions.shape}")
            return False
        
        # éªŒè¯æ•°å€¼èŒƒå›´
        action_min, action_max = actions.min().item(), actions.max().item()
        print(f"ğŸ“ˆ åŠ¨ä½œæ•°å€¼èŒƒå›´: [{action_min:.3f}, {action_max:.3f}]")
        
        print(f"ğŸ¯ Frankaå…¼å®¹æ€§éªŒè¯é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ Frankaå…¼å®¹æ€§éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_with_real_data():
    """ä½¿ç”¨çœŸå®Frankaæ•°æ®æµ‹è¯•æ¨¡å‹"""
    print(f"\nğŸ“ çœŸå®æ•°æ®æµ‹è¯•...")
    
    dataset_dir = "/home/wujielin/CascadeProjects/data/act_training/datasets/act_0918"
    if not os.path.exists(dataset_dir):
        print(f"âš ï¸ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        return False
    
    try:
        # è·å–ç¬¬ä¸€ä¸ªepisodeæ–‡ä»¶
        episode_files = sorted([f for f in os.listdir(dataset_dir) if f.endswith('.hdf5')])
        if not episode_files:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
            return False
            
        test_file = os.path.join(dataset_dir, episode_files[0])
        print(f"ğŸ“„ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {episode_files[0]}")
        
        with h5py.File(test_file, 'r') as f:
            # æ£€æŸ¥æ•°æ®æ ¼å¼
            qpos_data = f['/observations/qpos'][0]  # ç¬¬ä¸€å¸§
            image_data = f['/observations/images/top'][0]  # ç¬¬ä¸€å¸§å›¾åƒ
            action_data = f['/action'][0]  # ç¬¬ä¸€ä¸ªåŠ¨ä½œ
            
            print(f"âœ… çœŸå®æ•°æ®æ ¼å¼:")
            print(f"   qpos: {qpos_data.shape} å€¼åŸŸ: [{qpos_data.min():.3f}, {qpos_data.max():.3f}]")
            print(f"   image: {image_data.shape} å€¼åŸŸ: [{image_data.min():.0f}, {image_data.max():.0f}]")
            print(f"   action: {action_data.shape} å€¼åŸŸ: [{action_data.min():.3f}, {action_data.max():.3f}]")
            
            # éªŒè¯ç»´åº¦
            if qpos_data.shape[0] != 8:
                print(f"âŒ qposç»´åº¦é”™è¯¯: æœŸæœ›8, å®é™…{qpos_data.shape[0]}")
                return False
                
            if image_data.shape != (480, 640, 3):
                print(f"âŒ å›¾åƒç»´åº¦é”™è¯¯: æœŸæœ›(480, 640, 3), å®é™…{image_data.shape}")
                return False
                
            if action_data.shape[0] != 8:
                print(f"âŒ åŠ¨ä½œç»´åº¦é”™è¯¯: æœŸæœ›8, å®é™…{action_data.shape[0]}")
                return False
        
        print(f"âœ… çœŸå®æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="Franka ACTæ¨¡å‹å®Œæ•´éªŒè¯")
    parser.add_argument('--ckpt_path', type=str, 
                       default='/home/wujielin/CascadeProjects/data/act_training/checkpoints/franka_pick_place',
                       help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„æˆ–ç›®å½•')
    parser.add_argument('--skip_real_data', action='store_true',
                       help='è·³è¿‡çœŸå®æ•°æ®æµ‹è¯•')
    
    args = parser.parse_args()
    
    print("ğŸš€ Franka ACTæ¨¡å‹éªŒè¯å¼€å§‹...")
    print("=" * 50)
    
    # 1. çœŸå®æ•°æ®æµ‹è¯•ï¼ˆä¸ä¾èµ–æ¨¡å‹ï¼‰
    if not args.skip_real_data:
        data_valid = test_with_real_data()
        if not data_valid:
            print("âš ï¸ çœŸå®æ•°æ®éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­æ¨¡å‹éªŒè¯...")
    
    # 2. æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    ckpt_path = Path(args.ckpt_path)
    model_file = None
    
    if ckpt_path.is_dir():
        # ç›®å½•æ¨¡å¼ï¼šæŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹
        ckpt_files = list(ckpt_path.glob('policy_epoch_*.ckpt'))
        if not ckpt_files:
            print(f"âŒ åœ¨ {ckpt_path} ä¸­æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")
            print("ğŸ’¡ è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
            return
        
        # æŒ‰epochæ’åºï¼Œå–æœ€æ–°çš„
        ckpt_files.sort(key=lambda x: int(x.stem.split('_')[2]))
        model_file = ckpt_files[-1]
        print(f"ğŸ“ æ‰¾åˆ° {len(ckpt_files)} ä¸ªæ£€æŸ¥ç‚¹ï¼Œä½¿ç”¨æœ€æ–°çš„: {model_file.name}")
        
    elif ckpt_path.is_file():
        # æ–‡ä»¶æ¨¡å¼ï¼šç›´æ¥éªŒè¯
        model_file = ckpt_path
        print(f"ğŸ“„ ä½¿ç”¨æŒ‡å®šæ¨¡å‹æ–‡ä»¶: {model_file.name}")
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {ckpt_path}")
        return
    
    # 3. æ¨¡å‹æ£€æŸ¥ç‚¹éªŒè¯
    checkpoint_valid = model_validate(model_file)
    
    # 4. Frankaå…¼å®¹æ€§éªŒè¯
    if checkpoint_valid:
        franka_valid = validate_franka_compatibility(model_file)
    else:
        franka_valid = False
    
    # 5. æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“‹ éªŒè¯ç»“æœæ€»ç»“:")
    print("=" * 50)
    
    if not args.skip_real_data:
        status = "âœ… é€šè¿‡" if data_valid else "âŒ å¤±è´¥"
        print(f"çœŸå®æ•°æ®æµ‹è¯•    : {status}")
    
    status = "âœ… é€šè¿‡" if checkpoint_valid else "âŒ å¤±è´¥"
    print(f"æ¨¡å‹æ£€æŸ¥ç‚¹éªŒè¯  : {status}")
    
    status = "âœ… é€šè¿‡" if franka_valid else "âŒ å¤±è´¥"
    print(f"Frankaå…¼å®¹æ€§éªŒè¯: {status}")
    
    print("=" * 50)
    
    if checkpoint_valid and franka_valid:
        print("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼æ¨¡å‹å·²å‡†å¤‡å¥½ç”¨äºFrankaæœºå™¨äººï¼")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. éƒ¨ç½²æ¨¡å‹åˆ°æ¨ç†æœåŠ¡å™¨")
        print("   2. é…ç½®WebSocketæœåŠ¡")  
        print("   3. è¿æ¥å®¢æˆ·ç«¯è¿›è¡Œå®æ—¶æ¨ç†")
    else:
        print("âš ï¸ éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è®­ç»ƒæˆ–é…ç½®é—®é¢˜")

if __name__ == "__main__":
    main()
